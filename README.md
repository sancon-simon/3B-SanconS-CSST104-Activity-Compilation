# **3B-SanconS-CSST104-Activity-Compilation**

<h>CSST104-Activities</h>

<ul>
<li>
<a href="https://github.com/sancon-simon/3B-SanconS-CSST104-Activity-Compilation/blob/main/Compilation_Activities/Activity_1_Advance_Machine_Learning_(SanconS).ipynb" target = "_blank">Activity 1 - Advance Machine Learning</a>
</li>
  
<li>
<a href="https://github.com/sancon-simon/3B-SanconS-CSST104-Activity-Compilation/blob/main/Compilation_Activities/Activity_2_Simple_Linear_Regression(SanconS).ipynb" target = "_blank">Activity 2 - Simple Linear Regression</a>
</li>

<li>
<a href="https://github.com/sancon-simon/3B-SanconS-CSST104-Activity-Compilation/blob/main/Compilation_Activities/Activity_3_Multiple_Linear_Regression(SanconS).ipynb" target = "_blank">Activity 3 - Multiple Linear Regression</a>
</li>

<li>
<a href="https://github.com/sancon-simon/3B-SanconS-CSST104-Activity-Compilation/blob/main/Compilation_Activities/Activity_4_Titanic(SanconS).ipynb" target = "_blank">Activity 4 - Titanic</a>
</li>

</ul>

<h>CSST104-Exercises</h>

<ul>
<li>
<a href="https://github.com/sancon-simon/3B-SanconS-CSST104-Activity-Compilation/blob/main/Compilation_Exercises/3B_SANCON_EXER1.ipynb" target = "_blank">Exercise 1 - Advance Machine Learning</a>
</li>

<li>
<a href="https://github.com/sancon-simon/3B-SanconS-CSST104-Activity-Compilation/blob/main/Compilation_Exercises/3B_SANCON_EXER2.ipynb" target = "_blank">Exercise 2 - Advance Machine Learning</a>
</li>

<li>
<a href="https://github.com/sancon-simon/3B-SanconS-CSST104-Activity-Compilation/blob/main/Compilation_Exercises/3B_SANCON_EXER3.ipynb" target = "_blank">Exercise 3 - Advance Machine Learning</a>
</li>

<li>
<a href="https://github.com/sancon-simon/3B-SanconS-CSST104-Activity-Compilation/blob/main/Compilation_Exercises/3B_SANCON_EXER4.ipynb" target = "_blank">Exercise 4 - Advance Machine Learning</a>
</li>

<li>
<a href="https://github.com/sancon-simon/3B-SanconS-CSST104-Activity-Compilation/blob/main/Compilation_Exercises/3B_SANCON_EXER5.ipynb" target = "_blank">Exercise 5 - Advance Machine Learning</a>
</li>

<li>
<a href="https://github.com/sancon-simon/3B-SanconS-CSST104-Activity-Compilation/blob/main/Compilation_Exercises/3B_SANCON_EXER6.ipynb" target = "_blank">Exercise 6 - Advance Machine Learning</a>
</li>

<li>
<a href="https://github.com/sancon-simon/3B-SanconS-CSST104-Activity-Compilation/blob/main/Compilation_Exercises/3B_SANCON_EXER7.ipynb" target = "_blank">Exercise 7 - Advance Machine Learning</a>
</li>

<li>
<a href="https://github.com/sancon-simon/3B-SanconS-CSST104-Activity-Compilation/blob/main/Compilation_Exercises/3B_SANCON_EXER8.ipynb" target = "_blank">Exercise 8 - Advance Machine Learning</a>
</li>

<li>
<a href="https://github.com/sancon-simon/3B-SanconS-CSST104-Activity-Compilation/blob/main/Compilation_Exercises/3B_SANCON_MIDTERM.ipynb" target = "_blank">Midterm Exam - Advance Machine Learning</a>
</li>

</ul>

**Description**

Activities

*   [Activity 1]{#Activity-1}
*   [Activity 2](#Activity-2)
*   [Activity 3](#Activity-3)
*   [Activity 4](#Activity-4)

Exercises

*   [Exercise 1](#Exercise-1)
*   [Exercise 2](#Exercise-2)
*   [Exercise 3](#Exercise-3)
*   [Exercise 4](#Exercise-4)
*   [Exercise 4_2](#Exercise-4_2)
*   [Exercise 5](#Exercise-5)
*   [Exercise 6](#Exercise-6)
*   [Exercise 7](#Exercise-7)
*   [Exercise 8](#Exercise-8)
*   [Midterm Exam(9)](#Exercise-9)


**Activity-1**

This activity is focused on the Introduction of Advance Machine Learning, the dataset that was used is "hardwarestore.csv" this contains the following;

CATEGORY_NAME, 
Category_ID, 
Product_ID, 
STANDARD_COST, 
LIST_PRICE, 
REGION_ID, 
LOCATION_ID, 
WAREHOUSE_ID, 
QUANTITY

The Activity is Composed of basic data loading, data initial analysis, category analysis, cost and price analysis, location analysis as well as producing reports and insights.

**Activity-2**

This activity encompasses the fitting of simple linear regression model and visualizing the correlation linearity, the dataset that was used is called "Lesson_4_grades_dataset.csv"

In this activity the students(us) performed grouping crucial columns to select important features for fitting the model, The activity also includes visualizing data linearity, preparing data for modeling, fitting the linear regression model, getting the model coeficients, and visualizing the linear regression line.

**Activity-3**

In the third acticity the students(us) tackled multiple linear regression, the dataset that was used is similar to the one that was used in the previous activity the "Lesson_4_student_grades_dataset.csv", in here we performed feature selection using droping method, from there the dataset was split, to be prepared for initialization of the model.

After the inizialization, the linear regression was fitted, made predictions and evaluate it using MSE, The activity 3 is focused on predicting the grade of the student based on multiple numerical variables.

**Activity-4**

Thi Activity was quite short, the dataset that was utilized in the data analysis was called "titanic_data.csv" this dataset includes the following;

Survived, 
PassengerId, 
Pclass, 
Sex, 
Age, 
SibSp, 
Parch, 
Cabin, 
Embarked 

It incompasses data preparation identifying the survivor passengers, seperating the female and male passenger, and conducting correlational analysis, including visuzization of survavability across all variables

**Exercise-1**

The first exercise includes loading the dataset "sales_data.csv", in this performance task the students used data.describe for data loading and baisc data analysis, groupby methods was utilized for variable groping and feature selection and lastly the exercise produce report and insight before saving the code.

This exercise was focused on identifying the revenue of each product, the highest revenue product, ans product analysis visualization.

**Exercise-2**

The second activity is quite unique because the dataset was procudes by us the students by creating a dataframe then converting it into a .csv format, this activity includes the data analysis of student performace as it was focused on utilizing matplotlibs and seaborn in producing visualizations, in the forms of histograms, heatmaps and any other methods of graphing like bar graphs.

**Exercise-3**

Is also the application of Multiple Linear Regression the dataset was also random using the np.random.seed(), after creating the datase that includes;

Size, 
Bedrooms, 
Age, 
Price, 

After selecting feature and data spilitting the model was initialized for fitting and making predictions, MSE was used to evaluate the model and lastly  the testing of the predictive model.

**Exercise-4**

Was cut short as because of the class schedule reasons, this was the application of Logistic Regression were categorical variable was utilized instead of numerical in prediction, In here there are alot of libraries that was utilized, including Standard Scaler, Pipeline, train_test_split, One hot encoder etc.

The dataset that was used is called "titanic.csv", from there the students selected important features and variables, preprocess the data, using imputer and standard scaler, encode categorical variables and transform column for training the model after fitting.

**Exercise-4_2**

Is another Logistic Regression Performance, in here we use a dataset called "StudentPerformance.csv", it contains different score of students in several subject such as math and reading, from there the activity intends to split the data in to training and testing data sets, although before this it is a must to encode it into categorical variables because we are dealing with logistic regression, the y was selected by filtering the passed grades below and above 50
where below is a faling performance, after this is he usual the splitting, fitting and evaluation.

**Exercise-5**

Is title time siries analysis, this includes importing necessary libraries loading the dataset "sales-of-shampoo-over-a-three-ye.csv", The activity tackels the visualization of the sales time series using matplotlib, but before any of this it is crucial that the date is in the right format for a better trend visualization.

The activity includes the utiluzation of the arima model in forecasting the sales of shampoo over three year period.

**Exercise-6**

Exercise 6 is an assesment task it is for predicting feedback on online food orders using logistic regression.

The objective was to develop a logistic regression model to predict the customer feedback (positive/negative) on online food orders. The dataset to be utilized t contains information on online food orders, including customer demographics, order details, and feedback. The dataset includes features like;
 
Age, Gender, Marital Status, Occupation, Monthly Income, and Feedback.

**Assesment Requirements:**

1.   Data Exploration
2.   Exploratory Data Analysis(EDA)
3.   Logistic Regression
4.   Data Analysis and Visulization

**Exercise-7**

Exercise 7 in about Analyzing the Netflix Userbase. The student is expected to Leverage linear regression to predict Monthly Revenue and logistic regression to classify customers based on a positive or negative feedback proxy, using the Netflix Userbase dataset. 

The dataset to be utilized was called "Netflix Userbase.csv", containing user demographics, subscription details, and other relevant 
information.

**Assessment Requirements**

1. Data Preprocessing
2. Exploratory Data Analysis(EDA)
3. Linear Regression Model(Predicting Monthly Revenue)
4. Logistic Regression Model(Predicting Customer Feedback)
5. Comprative Analysis and Visualiztion

**Exercise-8**

Exercise 7 focuses on analyzing pollution data time series using ARIMA, The goal of this assessment is to simulate a time series dataset representing a country's annual pollution levels over a decade. The student was tasked to simulate a time series dataset for a country's annual pollution levels over 10 years. Assume a trend component, a seasonal component, and some random noise in the data.

The to be used "most-polluted-countries.csv" contains several columns related to pollution and country characteristics for the year 2023. 

**Assesment Requirents**

1. Data Preparation
2. Stationarity Testing
3. ARIMA Model Identification
4. ARIMA Model Fitting
5. Forecasting 
6. Report and Insights

**Exercise-9(Midterm exam)**

Entitled Time Series Analysis and Forecasting with ARIMA Model, The mid term exam expects to apply ARIMA modeling techniques to forecast the number of app updates in the Google Play Store for the next 12 months based on historical data

**Assesment Requirements**

1. Data Cleaning and Preparation
2. Exploratory Analysis (EDA)
3. Categoty Analysis
4. Rating Prediction Model
5. Trend Analysis
6. Impact of Reviews in Ratings
